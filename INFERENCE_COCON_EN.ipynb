{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just to inspect COCON model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger, basicConfig\n",
    "import sys\n",
    "from typing import List\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import torch\n",
    "from ptutils import count_params\n",
    "from transformers import (\n",
    "    GPT2Config, \n",
    "    GPT2Tokenizer,\n",
    "    GPT2LMHeadModel,\n",
    "    CoconBlock\n",
    ")\n",
    "from utils.utils import set_seed, fix_state_dict_naming\n",
    "\n",
    "from args import get_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    \"this_file.py\",\n",
    "    \"--do_cocon_compute\",\n",
    "    \"--output_dir\", \"models/COCON\",\n",
    "    \"--cocon_output_filename\", \"computers_cocon_output.txt\",\n",
    "    \"--cocon_output_jsonl_filename\", \"computers_cocon_output.jsonl\",\n",
    "    \"--model_type\", \"gpt2\",\n",
    "    \"--model_name_or_path\", \"gpt2-medium\",\n",
    "    \"--output_hidden_for_cocon_after_block_ind\", \"6\",\n",
    "    \"--per_gpu_eval_batch_size\", \"1\",\n",
    "    \"--prepend_bos_token_to_line\",\n",
    "    \"--gen_cs_len\", \"5\",\n",
    "    \"--generate_length\", \"80\",\n",
    "    \"--line_by_line_cs\",\n",
    "    \"--line_by_line_hs\",\n",
    "    \"--enumerate_all_cs_for_each_hs\",\n",
    "    \"--seed\", \"42\"\n",
    "]\n",
    "\n",
    "\n",
    "args = get_args()\n",
    "args.n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicConfig(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu:0\"\n",
    "model_name = \"gpt2-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "config = GPT2Config.from_pretrained(model_name)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-medium-pytorch_model.bin from cache at /home/nptdat/.cache/torch/transformers/4b337a4f3b7d3e1518f799e238af607498c02938a3390152aaec7d4dabca5a02.8769029be4f66a5ae1055eefdd1d11621b901d510654266b8681719fff492d6e\n"
     ]
    }
   ],
   "source": [
    "# Load GPT2 model\n",
    "model = GPT2LMHeadModel.from_pretrained(\n",
    "    model_name,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    cache_dir=None,\n",
    "    output_meanvars=True,\n",
    "    compute_meanvars_before_layernorm=False\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_gpt2:CoconBlock initialized\n"
     ]
    }
   ],
   "source": [
    "# Load CoconBlock\n",
    "cocon_block = CoconBlock(config.n_ctx, config, scale=True)\n",
    "cocon_state_dict = torch.load(\"models/COCON/cocon_block_pytorch_model.bin\")\n",
    "new_cocon_state_dict = fix_state_dict_naming(cocon_state_dict)\n",
    "cocon_block.load_state_dict(new_cocon_state_dict)\n",
    "\n",
    "cocon_block = cocon_block.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params of GPT2LMHeadModel: 354,823,168\n",
      "Num params of CoconBlock: 14,697,472\n"
     ]
    }
   ],
   "source": [
    "print(f\"Num params of {model.__class__.__name__}: {count_params(model):,}\")\n",
    "print(f\"Num params of CoconBlock: {count_params(cocon_block):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_topic(prompt_text, context, model, cocon_block, tokenizer, args, device):\n",
    "    prompt_seq = tokenizer.encode(\n",
    "        tokenizer.bos_token + prompt_text, \n",
    "        add_special_tokens=False, \n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    if context:\n",
    "        print(\"--- Generate with CoconBlock based on GPT-2\")\n",
    "        # Generate with CoconBlock based on GPT-2\n",
    "        context_seq = tokenizer.encode(context, add_special_tokens=False, return_tensors=\"pt\").to(device)\n",
    "        output_sequences = model.generate(\n",
    "            input_ids=prompt_seq[:, 0:0],\n",
    "            max_length=args.generate_length,\n",
    "            temperature=args.temperature,\n",
    "            top_k=args.k,\n",
    "            top_p=args.p,\n",
    "            repetition_penalty=args.repetition_penalty,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=args.num_return_sequences,\n",
    "            do_cocon=True,\n",
    "            cocon_block=cocon_block,\n",
    "            cocon_context_inputs=context_seq,\n",
    "            cocon_history_inputs=prompt_seq,\n",
    "            cocon_after_block_ind=args.output_hidden_for_cocon_after_block_ind,\n",
    "            transform_h_after_layernorm=False,\n",
    "            use_only_last_cocon_output_for_ar=args.use_only_last_cocon_output_for_ar,\n",
    "            context_attn_bias=-5\n",
    "        )\n",
    "        output_sequences = torch.cat([prompt_seq, output_sequences], dim=1)\n",
    "    else:\n",
    "        print(\"--- Generate with GPT-2 only\")\n",
    "        # Generate with GPT-2 only\n",
    "        output_sequences = model.generate(\n",
    "            input_ids=prompt_seq,\n",
    "            max_length=args.generate_length,\n",
    "            temperature=args.temperature,\n",
    "            top_k=args.k,\n",
    "            top_p=args.p,\n",
    "            repetition_penalty=args.repetition_penalty,\n",
    "            do_sample=True,\n",
    "            num_return_sequences=args.num_return_sequences\n",
    "        )\n",
    "\n",
    "    return tokenizer.decode(output_sequences[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best & simplest generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with GPT-2 only\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>It is listed on the Tokyo Stock Exchange, where it has been available in thin sheet form for five years. When I asked Mr Mair whether he sold the 6mg (18mg, 21mg, 26mg, and 32mg units in the United States, he smiled and said: \"I have gotten to about 50 out of 52 right now, and I\\'ll continue to get them to'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"It is listed on the Tokyo Stock Exchange, where\", \"\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>Toshiba Corporation is a Japanese consumer electronics company based in Japan, established in 1993, in the Western region of Japan.\\n\\nThe company was founded as a professional electronics company, setting its commercial objective to produce and market high-end electronic devices with reliable performance and affordable prices for Japanese consumers.\\n\\nIn 2001, it was renamed Toshiba Corporation, creating its modern manufacturing business models.\\n\\nSince then, Toshiba Corporation'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"Toshiba Corporation is a Japanese\", \"stock\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|endoftext|>Toshiba Corporation is a Japanese electronics company headquartered in Taipei. It's main business is in manufacturing and selling portable electronic equipment and solutions. The company's main activities include the production, assembly, and sale of products for commercial and industrial use. In the 1990s the company's main business was to develop and produce the entry level electronics that have traditionally been sold on the traditional electronics market. It became the world's largest electronics company\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"Toshiba Corporation is a Japanese\", \"finance\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>Toshiba Corporation is a Japanese conglomerate that makes PC software products and media players, including numerous multimedia software titles, and similar products such as video game consoles, video game controllers, and several personal computers. For more information about Toshiba Corporation, please visit our website at http://www.toshiba.co.jp/.\\n\\nUPDATES\\n\\n(8/28/2018) — Toshiba has announced that it'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"Toshiba Corporation is a Japanese\", \"computer\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|endoftext|>In summary, the Senate scandal is nearing its end, with reports that senators are suffering from hypothermia and questioning whether it is still an issue for the nation's flagship university.\\n\\nMultiple senators told CNN that Sen. Al Franken and Sen. Orrin Hatch were taken out of bed early Friday morning for a routine fitness test.\\n\\nA source told CNN that Hatch, now speaking to reporters in his\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"In summary\", \"scandal\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|endoftext|>In summary, you can actually build websites. Any computers can do this. There are even online forums dedicated to computing where you can talk about it.\\n\\nAll of this can be done with a few simple, inexpensive devices that do just that. The most common ones are very simple, and most people don't want to make money on the hardware they develop.\\n\\nThere are also devices that can do\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"In summary\", \"computers\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>In summary:\\n\\nOn 28th April 2017 a craft helicopter was used by E-Bomb to bomb the largest oil field in Iraq, Hashd al-Shaabi (Infantry Brigade), located on the Khanaqin-El-Khadiba (ISIS-controlled) oil field, a distance of 800km.\\n\\nAs the craft was acting as a military helicopter, it was able'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"In summary\", \"legal\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>In summary, this article illustrates the ideal situation where an adult player or \"player\" is trading a certain amount of time for a certain amount of money. A player could be doing something good or doing something bad and the amount of time the person is involved can be used as a proxy for the value that the player gets from that transaction.\\n\\nThis post discusses the ideal situation in which an adult player or'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"In summary\", \"science\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>Prior to this video, machines were equipped with hardware that was capable of processing data on a visual and/or auditory level. For example, computer systems can perform mathematical calculations that allow information to be obtained and stored in multiple locations simultaneously.\\n\\nHowever, for the past few years, the field of audio/visual processing has been dominated by scientific devices. These devices include audio/visual analyzers that can perform calculations'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"Prior to this\", \"computers\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|endoftext|>The key aspect of human cognition is the electric connections between neurons. This brain wiring is closely linked to the brain's chemical excitation of nerve cells and acts as a control system that regulates the behaviour of those nerve cells. The brain also has a sensor that senses the neurotransmitter, serotonin, in the body.\\n\\nSerotonin is a chemical that helps the brain regulate the activity of nerve cells and is known as\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"The key aspect\", \"computers\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generate with CoconBlock based on GPT-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"<|endoftext|>The key aspect of life in video game culture is playing Minecraft. Since its release in 2009, Minecraft has spawned a series of other games and services that have become very popular. While many of these games are based on the Minecraft server, there are also many others based on its lore, and they can be found all over the internet. Today we're going to talk about some of them. The Minecraft series has grown\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_topic(\"The key aspect\", \"japanese game industry\", model, cocon_block, tokenizer, args, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}